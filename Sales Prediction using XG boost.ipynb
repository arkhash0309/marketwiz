{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H1>Introduction</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3>Importing all the required tools and Reading the dataset</H3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "sales_df   =    pd.read_csv('Sales_Data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3>This is How the Dataset Looks like</H3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Product Quantity</th>\n",
       "      <th>Units sold</th>\n",
       "      <th>Day</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Category</th>\n",
       "      <th>DayType</th>\n",
       "      <th>Week_of_Year</th>\n",
       "      <th>Rainfall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-02</td>\n",
       "      <td>AMBEWELA SET YOGHURT</td>\n",
       "      <td>80ML</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>YOGHURT</td>\n",
       "      <td>Weekend</td>\n",
       "      <td>52</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>AMBEWELA SET YOGHURT</td>\n",
       "      <td>80ML</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>YOGHURT</td>\n",
       "      <td>Weekend</td>\n",
       "      <td>52</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>AMBEWELA SET YOGHURT</td>\n",
       "      <td>80ML</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>YOGHURT</td>\n",
       "      <td>Weekend</td>\n",
       "      <td>52</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>AMBEWELA SET YOGHURT</td>\n",
       "      <td>80ML</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>YOGHURT</td>\n",
       "      <td>Weekend</td>\n",
       "      <td>52</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-02</td>\n",
       "      <td>AMBEWELA SET YOGHURT</td>\n",
       "      <td>80ML</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>YOGHURT</td>\n",
       "      <td>Weekend</td>\n",
       "      <td>52</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34154</th>\n",
       "      <td>2023-10-09</td>\n",
       "      <td>HIGHLAND YOGHURT</td>\n",
       "      <td>80ML</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>2023</td>\n",
       "      <td>Monday</td>\n",
       "      <td>YOGHURT</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>41</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34155</th>\n",
       "      <td>2023-10-09</td>\n",
       "      <td>HIGHLAND YOGHURT</td>\n",
       "      <td>80ML</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>2023</td>\n",
       "      <td>Monday</td>\n",
       "      <td>YOGHURT</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>41</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34156</th>\n",
       "      <td>2023-10-09</td>\n",
       "      <td>HIGHLAND YOGHURT</td>\n",
       "      <td>80ML</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>2023</td>\n",
       "      <td>Monday</td>\n",
       "      <td>YOGHURT</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>41</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34157</th>\n",
       "      <td>2023-10-09</td>\n",
       "      <td>HIGHLAND YOGHURT</td>\n",
       "      <td>80ML</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>2023</td>\n",
       "      <td>Monday</td>\n",
       "      <td>YOGHURT</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>41</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34158</th>\n",
       "      <td>2023-10-09</td>\n",
       "      <td>HIGHLAND YOGHURT</td>\n",
       "      <td>80ML</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>2023</td>\n",
       "      <td>Monday</td>\n",
       "      <td>YOGHURT</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>41</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34159 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date          Product Name Product Quantity  Units sold  Day  \\\n",
       "0      2022-01-02  AMBEWELA SET YOGHURT             80ML           6    2   \n",
       "1      2022-01-01  AMBEWELA SET YOGHURT             80ML           6    1   \n",
       "2      2022-01-01  AMBEWELA SET YOGHURT             80ML           1    1   \n",
       "3      2022-01-01  AMBEWELA SET YOGHURT             80ML           6    1   \n",
       "4      2022-01-02  AMBEWELA SET YOGHURT             80ML          10    2   \n",
       "...           ...                   ...              ...         ...  ...   \n",
       "34154  2023-10-09      HIGHLAND YOGHURT             80ML          12    9   \n",
       "34155  2023-10-09      HIGHLAND YOGHURT             80ML           9    9   \n",
       "34156  2023-10-09      HIGHLAND YOGHURT             80ML          13    9   \n",
       "34157  2023-10-09      HIGHLAND YOGHURT             80ML           7    9   \n",
       "34158  2023-10-09      HIGHLAND YOGHURT             80ML           5    9   \n",
       "\n",
       "       Month  Year DayOfWeek Category  DayType  Week_of_Year  Rainfall  \n",
       "0          1  2022    Sunday  YOGHURT  Weekend            52       7.6  \n",
       "1          1  2022  Saturday  YOGHURT  Weekend            52       0.1  \n",
       "2          1  2022  Saturday  YOGHURT  Weekend            52       0.1  \n",
       "3          1  2022  Saturday  YOGHURT  Weekend            52       0.1  \n",
       "4          1  2022    Sunday  YOGHURT  Weekend            52       7.6  \n",
       "...      ...   ...       ...      ...      ...           ...       ...  \n",
       "34154     10  2023    Monday  YOGHURT  Weekday            41       0.0  \n",
       "34155     10  2023    Monday  YOGHURT  Weekday            41       0.0  \n",
       "34156     10  2023    Monday  YOGHURT  Weekday            41       0.0  \n",
       "34157     10  2023    Monday  YOGHURT  Weekday            41       0.0  \n",
       "34158     10  2023    Monday  YOGHURT  Weekday            41       0.0  \n",
       "\n",
       "[34159 rows x 12 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3>Quick overview</H3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date                0\n",
       "Product Name        0\n",
       "Product Quantity    0\n",
       "Units sold          0\n",
       "Day                 0\n",
       "Month               0\n",
       "Year                0\n",
       "DayOfWeek           0\n",
       "Category            0\n",
       "DayType             0\n",
       "Week_of_Year        0\n",
       "Rainfall            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Renaming the Dataframe and double checking that there are no null values</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= sales_df\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>QUICK EDA</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "sns.countplot(x='Category', data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot shows the comparison between the categry of products available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hammaad\\AppData\\Local\\Temp/ipykernel_18664/3094159044.py:2: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  sns.distplot(df['Rainfall'].values.flatten(), kde=False)  # Use flatten to convert any potential multi-dimensional array\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "sns.distplot(df['Rainfall'].values.flatten(), kde=False)  # Use flatten to convert any potential multi-dimensional array\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution of the rainfall along the dataset, many days had rainfall less than 12mm while there were server rainfalls till 100mm less frequently"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Algorithm - Random Forrest Classifier Accuracy (37.5%)</h1> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3706088992974239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hammaad\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "       BUTTER       0.00      0.00      0.00       225\n",
      "       CHEESE       0.04      0.00      0.00      1332\n",
      "       COFFEE       0.18      0.01      0.02      1667\n",
      "COLD BEVERAGE       0.12      0.00      0.01       959\n",
      "        FLOUR       0.00      0.00      0.00       653\n",
      "    ICE CREAM       0.20      0.02      0.04      1550\n",
      "      YOGHURT       0.38      0.97      0.54      3862\n",
      "\n",
      "     accuracy                           0.37     10248\n",
      "    macro avg       0.13      0.14      0.09     10248\n",
      " weighted avg       0.22      0.37      0.21     10248\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hammaad\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Hammaad\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Encode categorical features\n",
    "df = sales_df\n",
    "label_encoder = LabelEncoder()\n",
    "df['DayOfWeek'] = label_encoder.fit_transform(df['DayOfWeek'])\n",
    "df['DayType'] = label_encoder.fit_transform(df['DayType'])\n",
    "\n",
    "# Define features (X) and target variable (y)\n",
    "features = ['Day', 'Month', 'Year', 'DayOfWeek', 'DayType', 'Rainfall', 'Week_of_Year']\n",
    "target = 'Category'\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Create a RandomForestClassifier \n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Display additional classification metrics\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy is 37% using Random forrest classifier with 60 - 30 Train test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Tuning Hyper Parameters</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3751463700234192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hammaad\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Hammaad\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "       BUTTER       0.00      0.00      0.00       147\n",
      "       CHEESE       0.00      0.00      0.00       876\n",
      "       COFFEE       0.21      0.02      0.03      1095\n",
      "COLD BEVERAGE       0.12      0.00      0.01       631\n",
      "        FLOUR       0.00      0.00      0.00       416\n",
      "    ICE CREAM       0.20      0.02      0.03      1056\n",
      "      YOGHURT       0.38      0.97      0.55      2611\n",
      "\n",
      "     accuracy                           0.38      6832\n",
      "    macro avg       0.13      0.14      0.09      6832\n",
      " weighted avg       0.22      0.38      0.22      6832\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hammaad\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Display additional classification metrics\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy is 37% using Random forrest classifier with 80 - 20 Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3754391100702576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hammaad\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Hammaad\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "       BUTTER       0.00      0.00      0.00       147\n",
      "       CHEESE       0.00      0.00      0.00       876\n",
      "       COFFEE       0.21      0.02      0.03      1095\n",
      "COLD BEVERAGE       0.00      0.00      0.00       631\n",
      "        FLOUR       0.00      0.00      0.00       416\n",
      "    ICE CREAM       0.20      0.02      0.03      1056\n",
      "      YOGHURT       0.38      0.97      0.55      2611\n",
      "\n",
      "     accuracy                           0.38      6832\n",
      "    macro avg       0.11      0.14      0.09      6832\n",
      " weighted avg       0.21      0.38      0.22      6832\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hammaad\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Display additional classification metrics\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy is improving at a negligible rate after doubling the no of descion trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3744145199063232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hammaad\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Hammaad\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "       BUTTER       0.00      0.00      0.00       147\n",
      "       CHEESE       0.00      0.00      0.00       876\n",
      "       COFFEE       0.19      0.02      0.03      1095\n",
      "COLD BEVERAGE       0.12      0.00      0.01       631\n",
      "        FLOUR       0.00      0.00      0.00       416\n",
      "    ICE CREAM       0.19      0.02      0.03      1056\n",
      "      YOGHURT       0.38      0.96      0.55      2611\n",
      "\n",
      "     accuracy                           0.37      6832\n",
      "    macro avg       0.13      0.14      0.09      6832\n",
      " weighted avg       0.22      0.37      0.22      6832\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hammaad\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=50, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Display additional classification metrics\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy isnt affected significantly after tuning the no of decision trees used in the algorithm therefore all the possible hyper parameters are tuned therefore We should try another alogorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Algorithm - xGBoost Classifier Accuracy</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.37719555035128804\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       147\n",
      "           1       0.00      0.00      0.00       876\n",
      "           2       0.24      0.01      0.02      1095\n",
      "           3       0.00      0.00      0.00       631\n",
      "           4       0.00      0.00      0.00       416\n",
      "           5       0.19      0.02      0.03      1056\n",
      "           6       0.38      0.98      0.55      2611\n",
      "\n",
      "    accuracy                           0.38      6832\n",
      "   macro avg       0.12      0.14      0.09      6832\n",
      "weighted avg       0.21      0.38      0.22      6832\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hammaad\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Hammaad\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Hammaad\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load your dataset\n",
    "# Assuming 'df' is your DataFrame\n",
    "# Make sure 'Category' column has the categorical labels\n",
    "\n",
    "# Encode categorical features\n",
    "label_encoder = LabelEncoder()\n",
    "df['DayOfWeek'] = label_encoder.fit_transform(df['DayOfWeek'])\n",
    "df['DayType'] = label_encoder.fit_transform(df['DayType'])\n",
    "\n",
    "# Encode the categorical target variable\n",
    "df['Category'] = label_encoder.fit_transform(df['Category'])\n",
    "\n",
    "# Define features (X) and target variable (y)\n",
    "features = ['Day', 'Month', 'Year', 'DayOfWeek', 'DayType', 'Rainfall', 'Week_of_Year']\n",
    "target = 'Category'\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create an XGBClassifier\n",
    "clf = XGBClassifier(objective='multi:softmax', random_state=42)\n",
    "\n",
    "# Train the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Decode the predictions back to original labels if needed\n",
    "y_pred_labels = label_encoder.inverse_transform(y_pred)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Display additional classification metrics\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy is 37% without tuning hyper parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Tuning Hyper Parameters</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.37983021077283374\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       147\n",
      "           1       0.00      0.00      0.00       876\n",
      "           2       0.43      0.00      0.01      1095\n",
      "           3       0.00      0.00      0.00       631\n",
      "           4       0.00      0.00      0.00       416\n",
      "           5       0.11      0.00      0.01      1056\n",
      "           6       0.38      0.99      0.55      2611\n",
      "\n",
      "    accuracy                           0.38      6832\n",
      "   macro avg       0.13      0.14      0.08      6832\n",
      "weighted avg       0.23      0.38      0.21      6832\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hammaad\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Hammaad\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Hammaad\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create an XGBClassifier\n",
    "clf = XGBClassifier(objective='multi:softmax', random_state=42, learning_rate=0.1)\n",
    "\n",
    "# Train the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Decode the predictions back to original labels if needed\n",
    "y_pred_labels = label_encoder.inverse_transform(y_pred)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Display additional classification metrics\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the golden triple values for the leaning rate. 37.9% after 0.1 learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.38129391100702575\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       147\n",
      "           1       0.00      0.00      0.00       876\n",
      "           2       0.00      0.00      0.00      1095\n",
      "           3       0.00      0.00      0.00       631\n",
      "           4       0.00      0.00      0.00       416\n",
      "           5       0.15      0.00      0.00      1056\n",
      "           6       0.38      1.00      0.55      2611\n",
      "\n",
      "    accuracy                           0.38      6832\n",
      "   macro avg       0.08      0.14      0.08      6832\n",
      "weighted avg       0.17      0.38      0.21      6832\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hammaad\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Hammaad\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Hammaad\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create an XGBClassifier\n",
    "clf = XGBClassifier(objective='multi:softmax', random_state=42, learning_rate=0.03)\n",
    "\n",
    "# Train the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Decode the predictions back to original labels if needed\n",
    "y_pred_labels = label_encoder.inverse_transform(y_pred)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Display additional classification metrics\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy increased to 38% after lowering the learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.382172131147541\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       147\n",
      "           1       0.00      0.00      0.00       876\n",
      "           2       0.00      0.00      0.00      1095\n",
      "           3       0.00      0.00      0.00       631\n",
      "           4       0.00      0.00      0.00       416\n",
      "           5       0.00      0.00      0.00      1056\n",
      "           6       0.38      1.00      0.55      2611\n",
      "\n",
      "    accuracy                           0.38      6832\n",
      "   macro avg       0.05      0.14      0.08      6832\n",
      "weighted avg       0.15      0.38      0.21      6832\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hammaad\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Hammaad\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Hammaad\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create an XGBClassifier\n",
    "clf = XGBClassifier(objective='multi:softmax', random_state=42, learning_rate=0.001, n_estimators=1000, max_depth=5)\n",
    "\n",
    "# Train the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Decode the predictions back to original labels if needed\n",
    "y_pred_labels = label_encoder.inverse_transform(y_pred)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Display additional classification metrics\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy increased to 38.2% after lowering the learning rate and adding more decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
